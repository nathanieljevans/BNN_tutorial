{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Neural Networks \n",
    "\n",
    "This script explores using pytorch and pyro to build, train and test a bayesian neural network. The advantage and novelty of this model is that inference is done probablistically; thereby allowing us to quantify the certainty of model results. Kind of like a built in sensitivity  analysis. \n",
    "\n",
    "I like the way [this](https://towardsdatascience.com/making-your-neural-network-say-i-dont-know-bayesian-nns-using-pyro-and-pytorch-b1c24e6ab8cd) [3] tutorial phrases it:  \n",
    "\n",
    "> Making Your Neural Network Say “I Don’t Know”\n",
    "\n",
    "In this tutorial, we'll go over \n",
    "- key differences of `Bayesian Neural Networks (BNN)` vs `Neural Networks (NN)` \n",
    "- how BNNs do inference & training \n",
    "- simple tutorial on how to build a BNN using `pytorch` and `pyro` \n",
    "- difference in training and prediction time complexity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BNNs vs NNs \n",
    "\n",
    "## Classic Neural Network \n",
    "\n",
    "\n",
    "## Bayesian Neural Network \n",
    "\n",
    "![image.png](https://www.researchgate.net/profile/Florian_Haese/publication/329843608/figure/fig2/AS:713727343067138@1547177267367/llustration-of-a-Bayesian-Neural-Network-BNN-A-A-Bayesian-neuron-defines-a_W640.jpg)\n",
    "Taken from [1]. \n",
    "\n",
    "\n",
    "# BNN advantage\n",
    "\n",
    "\n",
    "## What happens when you give cutting edge neural network an image of noise? \n",
    "\n",
    "![image.png](https://miro.medium.com/max/802/0*HG51qQU8I34_fUgB.jpg)\n",
    "\n",
    "--- \n",
    "\n",
    "The most obvious advantage of these BNNs are that they allow the model to propogate it's uncertainty about a prediction, from [this]( https://krasserm.github.io/2019/03/14/bayesian-neural-networks/) tutorial, there is a great plot that shows this.\n",
    "\n",
    "![image.png](https://krasserm.github.io/img/2019-03-14/output_9_1.png)\n",
    "\n",
    "From this we can see that the BNN knows where in it's feature space it has accurate predictions, and where it does not. I've been thinking about this as a built in sensitivity analysis. With a few extra lines of code, we can have the model say, \"Hey, I don't know what the answer is, don't trust me\", which is a key feature when making important decisions. \n",
    "\n",
    "Other advantages include being able to include priors on our weight distributions (could be tough to know how to do this well). Also priors on our X distributions, which could be as simple as calculating p(x) over each mini-batch of the training set and using this as the prior on test sets. \n",
    "\n",
    "# Training a BNN \n",
    "\n",
    "## Variation Inference \n",
    "\n",
    "\n",
    "## Sampling \n",
    "\n",
    "\n",
    "# Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import relevant packages\n",
    "import torch\n",
    "import torch.nn.functional as nnf\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.optim import SGD \n",
    "from torch.distributions import constraints\n",
    "import torchvision as torchv\n",
    "import torchvision.transforms as torchvt\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "from torch import nn\n",
    "from pyro.infer import SVI, TraceMeanField_ELBO\n",
    "import pyro\n",
    "from pyro import poutine\n",
    "import pyro.optim as pyroopt\n",
    "import pyro.distributions as dist\n",
    "import pyro.contrib.bnn as bnn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.distributions.utils import lazy_property\n",
    "import math\n",
    "from torch.utils import data\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X,Y = load_iris(return_X_y=True)\n",
    "\n",
    "for i,x in enumerate(X): \n",
    "    torch.save(torch.tensor(x), './data/%d.pt' %i) \n",
    "\n",
    "n_classes=len(set(Y))\n",
    "\n",
    "partition = {'train':range(0,100), \n",
    "             'val':range(100,125),\n",
    "             'test':range(125,151)}\n",
    "\n",
    "labels = {str(i):j for i,j in zip(range(151), Y)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Dataset(data.Dataset):\n",
    "  'Characterizes a dataset for PyTorch'\n",
    "  def __init__(self, list_IDs, labels):\n",
    "        'Initialization'\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "\n",
    "  def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.list_IDs)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        ID = self.list_IDs[index]\n",
    "\n",
    "        # Load data and get label\n",
    "        X = torch.load('data/' + ID + '.pt')\n",
    "        y = self.labels[ID]\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CUDA for PyTorch\n",
    "device = torch.device('cpu')\n",
    "\n",
    "# Parameters\n",
    "params = {'batch_size': 50,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 6}\n",
    "\n",
    "# Generators\n",
    "training_set = Dataset(partition['train'], labels)\n",
    "train_loader = data.DataLoader(training_set, **params)\n",
    "\n",
    "validation_set = Dataset(partition['val'], labels)\n",
    "validation_generator = data.DataLoader(validation_set, **params)\n",
    "\n",
    "test_set = Dataset(partition['test'], labels)\n",
    "test_generator = data.DataLoader(test_set, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FCN(nn.Module):\n",
    "    def __init__(self, n_classes=n_classes):\n",
    "        super(FCN, self).__init__()\n",
    "        self.fc = nn.Sequential(nn.Dropout(p=0.2),\n",
    "                                nn.Linear(4, 20),\n",
    "                                nn.Dropout(p=0.9),\n",
    "                                nn.LeakyReLU(),\n",
    "                                nn.Linear(20,50),\n",
    "                                nn.Dropout(p=0.9),\n",
    "                                nn.LeakyReLU(),\n",
    "                                nn.Linear(50, 20),\n",
    "                                nn.Dropout(p=0.9),\n",
    "                                nn.LeakyReLU(),\n",
    "                                nn.Linear(20, n_classes),\n",
    "                                nn.LogSoftmax(dim=-1))\n",
    "    \n",
    "    def forward(self, inp):\n",
    "        return self.fc(inp)\n",
    "\n",
    "FC_NN = FCN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can't convert 'int' object to str implicitly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-db92107fefff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mcorrect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mFC_NN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 346\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-958225e7c54d>\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;31m# Load data and get label\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mID\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.pt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Can't convert 'int' object to str implicitly"
     ]
    }
   ],
   "source": [
    "optim = SGD(FC_NN.parameters(recurse=True), lr=0.1, momentum=0.95)\n",
    "epochs = 100\n",
    "\n",
    "for i in range(epochs):\n",
    "    total_loss = 0.0 \n",
    "    total = 0.0\n",
    "    correct = 0.0\n",
    "    for x, y in train_loader:\n",
    "        \n",
    "        FC_NN.zero_grad()\n",
    "        pred = FC_NN.forward(x)\n",
    "        loss = nnf.binary_cross_entropy_with_logits(pred, nnf.one_hot(y, n_classes).float())\n",
    "        total_loss += loss\n",
    "        total += labels.size(0)\n",
    "        correct += (pred.argmax(-1) == y).sum().item()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    \n",
    "    print('epoch: %d | loss: %.3f | acc: %.5f' %((i+1), total_loss, correct/total*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References \n",
    "\n",
    "1.How machine learning can assist the interpretation of ab initio molecular dynamics simulations and conceptual understanding of chemistry. ResearchGate https://www.researchgate.net/publication/329843608_How_machine_learning_can_assist_the_interpretation_of_ab_initio_molecular_dynamics_simulations_and_conceptual_understanding_of_chemistry/figures?lo=1.\n",
    "\n",
    "2.Variational inference for Bayesian neural networks - Martin Krasser’s Blog. https://krasserm.github.io/2019/03/14/bayesian-neural-networks/.\n",
    "\n",
    "3.Chopra, P. Making Your Neural Network Say “I Don’t Know” — Bayesian NNs using Pyro and PyTorch. Medium https://towardsdatascience.com/making-your-neural-network-say-i-dont-know-bayesian-nns-using-pyro-and-pytorch-b1c24e6ab8cd (2019).\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
